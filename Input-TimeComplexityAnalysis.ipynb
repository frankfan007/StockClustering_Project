{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ClusteringAlg3 as lf\n",
    "import georgeVersion as gp\n",
    "import StockMarketClustering as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Time Complexity of Clustering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory\n",
    "\n",
    "If we take $n$ is the number of firms that we have in the dataset, and $k$ as the number of iterations, the algorithm follows some key properties:\n",
    "* After the $k$th iteration, the maximum number of firms in a cluster is min(k+1,n), as one can simply add a link to a \"new\" node in every iteration, starting from k=0 where all clusters are of size 1, and one can do this up until all nodes have been connected.\n",
    "* After the $k$th iteration, the minimum number of clusters is max(1,n-k), which corresponds to the case above.\n",
    "* After the $k$th iteration, the maximum number of clusters is between n and n-k, in fact the maximum number of clusters is n minus the maximum number that when triangled, is less than n - specifically this is $n +  \\left \\lfloor{\\frac{1- \\sqrt{1+8k}}{2}}\\right \\rfloor$.\n",
    "\n",
    "This second fact can be seen iteratively by considering the highest number of possible elements within a single cluster, building up on one maximally connected cluster will leave the remaining nodes as their own individual clusters, and therefore have the highest number of clusters.\n",
    "* After the first iteration, two nodes that are not part of the same set must be merged together. (e.g. A-B). The maximal number of clusters is n-1.\n",
    "* After the second iteration, again two nodes that are not part of the same set must be merged together (e.g. B-C), as the cluster contains only two nodes, whose correlation has already been \"used\". The maximal number of clusters is n-2.\n",
    "* After the third iteration, one new node can be linked to one of the existing 2 nodes, (e.g. C-A), as the cluster is not yet complete. The maximal number of clusters is still n-2.\n",
    "* For the fourth to sixth iteration, the a new node can be added in turn to the existing 3-node connected cluster (e.g. A-D, B-D, C-D). The maximal number of clusters for this group will be n-3.\n",
    "* For the seventh to tenth iteration, one new node can be linked to each of the existing 4-node cluster. (e.g. A-E, B-E, C-E, D-E). The maximal number of clusters for this group will be n-4.\n",
    "\n",
    "This pattern, (n-1, n-2, n-2, n-3, n-3, n-3, n-4, n-4, n-4, n-4...) is n minus the reversed triangle number of k, which, when using the quadratic formula backwards from k, is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, the time complexity of the clustering algorithm is as follows:\n",
    "\n",
    "**Creating the set of firms** \n",
    "+ Constant time operation for initialising the set\n",
    "+ O($n^{2}$) operations to:\n",
    "    + Loop through every correlation $(n(n-1)/2)$ so O($n^{2}$)\n",
    "    + Add the firm to the set O(1)\n",
    "    \n",
    "**Converting the firm set into a dictionary** \n",
    "+ Constant time operation to initialise the dictionary\n",
    "+ n operations to create a dictionary entry per firm\n",
    "\n",
    "**Initialising the set of start nodes**\n",
    "+ Constant time to initialise the set of start nodes as the firm set (copy)\n",
    "\n",
    "**Core Iteration: Comparing and Merging** \n",
    "+ Loop is iterated $k$ times\n",
    "    + Constant time operation to pop an item from the list\n",
    "    + O($k$) time to find the bottom node from the source (as k is the maximum number of elements in a cluster at time k)\n",
    "    + O($k$) time to find the bottom node from the destination\n",
    "    + O($k$) time if the top node needs to be found from the destination\n",
    "    + Constant time to change the pointers for the required nodes, and remove an element from the set of start nodes\n",
    "    \n",
    "**Returning Sets** \n",
    "+ Loop is iterated per number of clusters, maximally $n$ - the reverse triangle of $k$ times, which is in the order O($n-\\sqrt{k}$)\n",
    "    + Inner loop is iterated per maximum number of elements in the cluster, which could be up to k\n",
    "    + Constant time operation to check if the node has a pointer to another node, and to add the node to the current set\n",
    "+ Constant time to add the current set to the list of sets\n",
    "\n",
    "So overall, the time complexity is O($n^2 + k^2 + k(n-\\sqrt{k})$), which can be reduced to O($n^2 + k^2$) because $k(n-\\sqrt{k})$ will always be less than $kn$ which is less than max($k^2, n^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we explore two alternative algorithms to the clustering algorithm, to determine the speed in practice for our dataset, this is done with multiple values for k. The algorithms in question are referred to as:\n",
    "* Algorithm 1: O($n^2 + k^2$), primarily using a dictionary of pointers\n",
    "* Algorithm 2: O($n^2 + k^2$), primarily using a dictionary of sets, and with a better average complexity than the above\n",
    "* Algorithm 3: O($kn^2$), primarily using sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firms = pd.read_csv('SP_500_firms.csv')\n",
    "close_prices = pd.read_csv('SP_500_close_2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dailyReturn = sm.stockReturns(close_prices)\n",
    "corr, corrGraph = sm.calCorrelations(dailyReturn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_list = gp.correlations(dailyReturn)\n",
    "ordered_list = gp.sortCorrs(correlation_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultssm = sm.stockClustering(corrGraph, 5000)\n",
    "clusterssm = [i for i in resultssm if len(i) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultsgp = gp.clusteringAlg(ordered_list, 5000)\n",
    "clustersgp = [i for i in resultsgp if len(i) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultslf = lf.ClusteringAlg3(ordered_list, 5000)\n",
    "clusterslf = [i for i in resultslf if len(i) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With k=50, the first algorithm performs as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 42.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 1 (LF)\n",
    "%timeit resultslf = lf.ClusteringAlg3(ordered_list, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second algorithm performs as below, which is somewhat slower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 179 ms per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 2 (SM)\n",
    "%timeit resultssm = sm.stockClustering(corrGraph, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third algorithm performs as below, which is slower than the two above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.52 s per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 3 (GP)\n",
    "%timeit resultsgp = gp.clusteringAlg(ordered_list, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With k=5000, the first algorithm performs as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 507 ms per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 1 (LF)\n",
    "%timeit resultslf = lf.ClusteringAlg3(ordered_list, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second algorithm performs as below, which is approximately twice as quick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 256 ms per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 2 (SM)\n",
    "%timeit resultssm = sm.stockClustering(corrGraph, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third algorithm performs as below, which is slower than the two above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.53 s per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 3 (GP)\n",
    "%timeit resultsgp = gp.clusteringAlg(ordered_list, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With k=15000, the first algorithm performs as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.98 s per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 1 (LF)\n",
    "%timeit resultslf = lf.ClusteringAlg3(ordered_list, 15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second algorithm performs as below, which is twice as quick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 527 ms per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 2 (SM)\n",
    "%timeit resultssm = sm.stockClustering(corrGraph, 15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third algorithm performs as below, which is slower than algorithm 2 get quicker than algorithm 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.71 s per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 3 (GP)\n",
    "%timeit resultsgp = gp.clusteringAlg(ordered_list, 15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With k=100000, the first algorithm performs as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 14.2 s per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 1 (LF)\n",
    "%timeit resultslf = lf.ClusteringAlg3(ordered_list, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.93 s per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 2 (SM)\n",
    "%timeit resultssm = sm.stockClustering(corrGraph, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.68 s per loop\n"
     ]
    }
   ],
   "source": [
    "## Time results Algorithm 3 (GP)\n",
    "%timeit resultsgp = gp.clusteringAlg(ordered_list, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as expected from the algorithmic complexity as algorithm 3 is linear rather than polynomial in k, and in our case k gets very large whereas n does not. In cases with a large n and a large k, the other algorithms may out perform."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
